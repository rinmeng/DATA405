# Create binned tenure categories
telco$tenure_bins <- cut(telco$tenure,
breaks = c(0, 12, 24, 36, 48, 60, Inf),
labels = c("0-12", "13-24", "25-36", "37-48", "49-60", "60+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = tenure_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by tenure Bins", x = "Tenure (Months)", y = "Proportion") +
theme_minimal()
telco$MonthlyCharges_bins <- cut(telco$MonthlyCharges,
breaks = c(0, 20, 40, 60, 80, 100, Inf),
labels = c("0-20", "21-40", "41-60", "61-80", "81-100", "100+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = MonthlyCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by MonthlyCharges Bins", x = "MonthlyCharges ($)", y = "Proportion") +
theme_minimal()
telco$TotalCharges_bins <- cut(telco$TotalCharges,
breaks = c(0, 800, 1600, 2400, 3200, 4000, 4800, Inf),
labels = c("0-800", "801-1600", "1601-2400", "2401-3200", "3201-4000", "4001-4800", "4800+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = TotalCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by TotalCharges Bins", x = "TotalCharges ($)", y = "Proportion") +
theme_minimal()
# First split: 70% training and 30% test
sampleSize <- floor(0.7 * nrow(telco))
set <- sample(seq_len(nrow(telco)), size = sampleSize)
telcoTrain_Pre <- telco[set, ]
telcoTest <- telco[-set, ]
paste("telcoTrain_Pre has", nrow(telcoTrain_Pre), "rows which is", sprintf("%.2f",100 * nrow(telcoTrain_Pre)/nrow(telco)), "% of the dataset")
paste("telcoTest has", nrow(telcoTest), "rows which is", sprintf("%.2f",100 * nrow(telcoTest)/nrow(telco)), "% of the dataset")
# Second split: 80% training and 20% validation from telcoTrain_Pre
trainSampleSize <- floor(0.8 * nrow(telcoTrain_Pre))
set <- sample(seq_len(nrow(telcoTrain_Pre)), size = trainSampleSize)
telcoTrain <- telcoTrain_Pre[set, ]
telcoValidate <- telcoTrain_Pre[-set, ]
paste("telcoTrain has", nrow(telcoTrain), "rows which is", sprintf("%.2f",100 * nrow(telcoTrain)/nrow(telcoTrain_Pre)), "% of the training set")
paste("telcoValidate has", nrow(telcoValidate), "rows which is", sprintf("%.2f",100 * nrow(telcoValidate)/nrow(telcoTrain_Pre)), "% of the training set")
telcoTrain.glm <- glm(Churn ~ tenure + MonthlyCharges + TotalCharges, data=telcoTrain, family= binomial)
summary(telcoTrain.glm)
# Now we use those predictors that is significant
telcoTrain.glm9 <- glm(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain, family=binomial)
summary(telcoTrain.glm9)
# Load necessary libraries
library(caret)
library(dplyr)
# Define the training control for cross-validation
train_control <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = k_values)
# Display the results
print(knn_model)
plot(knn_model)
# Load necessary libraries
library(caret)
library(dplyr)
# Define the training control for cross-validation
train_control <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = k_values)
# Display the results
print(knn_model)
plot(knn_model)
telco <- read.table(("telcochurn.csv"), header=TRUE, sep = ",")
telco <- na.omit(telco)
# Make sure its factored into levels Yes and No
telco$Churn <- as.factor(telco$Churn)
telco$tenure <- as.numeric(telco$tenure)
telco$gender <- as.factor(telco$gender)
telco$SeniorCitizen <- as.factor(telco$SeniorCitizen)
telco$Partner <- as.factor(telco$Partner)
telco$Dependents <- as.factor(telco$Dependents)
telco$PhoneService <- as.factor(telco$PhoneService)
telco$MultipleLines <- as.factor(telco$MultipleLines)
telco$InternetService <- as.factor(telco$InternetService)
telco$OnlineSecurity <- as.factor(telco$OnlineSecurity)
telco$OnlineBackup <- as.factor(telco$OnlineBackup)
telco$DeviceProtection <- as.factor(telco$DeviceProtection)
telco$TechSupport <- as.factor(telco$TechSupport)
telco$StreamingTV <- as.factor(telco$StreamingTV)
telco$StreamingMovies <- as.factor(telco$StreamingMovies)
telco$Contract <- as.factor(telco$Contract)
telco$PaperlessBilling <- as.factor(telco$PaperlessBilling)
telco$PaymentMethod <- as.factor(telco$PaymentMethod)
telco$MonthlyCharges <- as.numeric(telco$MonthlyCharges)
telco$TotalCharges <- as.numeric(telco$TotalCharges)
str(telco)
library(ggplot2)
ggplot(telco, aes(x = Churn)) +
geom_bar(fill = c("steelblue", "tomato")) +
labs(title = "Customer Churn Frequency",
x = "Churn Status",
y = "Frequency") +
theme_minimal()
churnPlot <- function(predictor) {
ggplot(telco, aes_string(x = predictor, fill = "Churn")) +  # Use aes_string for dynamic x aesthetic
geom_bar(position = "fill") +
labs(title = paste("Churn Rate by", predictor), x = predictor, y = "Proportion") +  # Make title dynamic
theme_minimal()
}
# Identify categorical predictors
predictors <- colnames(telco)
exclude_columns <- c("customerID","Churn", "MonthlyCharges", "TotalCharges","tenure")
predictors <- predictors[!predictors %in% exclude_columns]
for (predictor in predictors) {
print(churnPlot(predictor))
}
# Create binned tenure categories
telco$tenure_bins <- cut(telco$tenure,
breaks = c(0, 12, 24, 36, 48, 60, Inf),
labels = c("0-12", "13-24", "25-36", "37-48", "49-60", "60+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = tenure_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by tenure Bins", x = "Tenure (Months)", y = "Proportion") +
theme_minimal()
telco$MonthlyCharges_bins <- cut(telco$MonthlyCharges,
breaks = c(0, 20, 40, 60, 80, 100, Inf),
labels = c("0-20", "21-40", "41-60", "61-80", "81-100", "100+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = MonthlyCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by MonthlyCharges Bins", x = "MonthlyCharges ($)", y = "Proportion") +
theme_minimal()
telco$TotalCharges_bins <- cut(telco$TotalCharges,
breaks = c(0, 800, 1600, 2400, 3200, 4000, 4800, Inf),
labels = c("0-800", "801-1600", "1601-2400", "2401-3200", "3201-4000", "4001-4800", "4800+"),
right = FALSE,   # Include the lower bound, exclude the upper
include.lowest = TRUE)  # Include the lowest value
ggplot(telco, aes(x = TotalCharges_bins, fill = Churn)) +
geom_bar(position = "fill") +
labs(title = "Churn Rate by TotalCharges Bins", x = "TotalCharges ($)", y = "Proportion") +
theme_minimal()
set.seed(51940633)
# First split: 70% training and 30% test
sampleSize <- floor(0.7 * nrow(telco))
set <- sample(seq_len(nrow(telco)), size = sampleSize)
telcoTrain_Pre <- telco[set, ]
telcoTest <- telco[-set, ]
paste("telcoTrain_Pre has", nrow(telcoTrain_Pre), "rows which is", sprintf("%.2f",100 * nrow(telcoTrain_Pre)/nrow(telco)), "% of the dataset")
paste("telcoTest has", nrow(telcoTest), "rows which is", sprintf("%.2f",100 * nrow(telcoTest)/nrow(telco)), "% of the dataset")
# Second split: 80% training and 20% validation from telcoTrain_Pre
set.seed(51940633)
trainSampleSize <- floor(0.8 * nrow(telcoTrain_Pre))
set <- sample(seq_len(nrow(telcoTrain_Pre)), size = trainSampleSize)
telcoTrain <- telcoTrain_Pre[set, ]
telcoValidate <- telcoTrain_Pre[-set, ]
paste("telcoTrain has", nrow(telcoTrain), "rows which is", sprintf("%.2f",100 * nrow(telcoTrain)/nrow(telcoTrain_Pre)), "% of the training set")
paste("telcoValidate has", nrow(telcoValidate), "rows which is", sprintf("%.2f",100 * nrow(telcoValidate)/nrow(telcoTrain_Pre)), "% of the training set")
set.seed(51940633)
telcoTrain.glm <- glm(Churn ~ tenure + MonthlyCharges + TotalCharges, data=telcoTrain, family= binomial)
summary(telcoTrain.glm)
set.seed(51940633)
# Now we use those predictors that is significant
telcoTrain.glm9 <- glm(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain, family=binomial)
summary(telcoTrain.glm9)
set.seed(51940633)
# Load necessary libraries
library(caret)
library(dplyr)
# Define the training control for cross-validation
train_control <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = k_values)
# Display the results
print(knn_model)
plot(knn_model)
set.seed(51940633)
# Load necessary libraries
library(caret)
library(dplyr)
# Define the training control for cross-validation
train_control <- trainControl(method = "cv", number = 10)
# Train KNN model
# Specify a grid of k values (for example, from 1 to 20)
k_values <- data.frame(k = seq(1, 50, by = 1))  # Example k values
knn_model <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data=telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = k_values)
# Display the results
print(knn_model)
plot(knn_model)
library(caret)
library(dplyr)
set.seed(51940633)
train_control <- trainControl(method = "cv", number = 10)
optimal_k <- data.frame(k = 23)
knn_model_optimal <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data = telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = optimal_k)
print(knn_model_optimal)
library(caret)
library(dplyr)
set.seed(51940633)
train_control <- trainControl(method = "cv", number = 10)
optimal_k <- data.frame(k = knn_model$bestTune$k)
optimal_k
knn_model_optimal <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data = telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = optimal_k)
print(knn_model_optimal)
library(caret)
library(dplyr)
set.seed(51940633)
train_control <- trainControl(method = "cv", number = 10)
knn_model_optimal <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data = telcoTrain,
method = "knn",
trControl = train_control,
k = 23)
library(caret)
library(dplyr)
set.seed(51940633)
train_control <- trainControl(method = "cv", number = 10)
optimal_k <- data.frame(k = knn_model$bestTune$k)
knn_model_optimal <- train(Churn ~ SeniorCitizen + tenure + Contract +
PaymentMethod + PaperlessBilling +
OnlineSecurity + TechSupport + StreamingMovies +
InternetService + MonthlyCharges + TotalCharges,
data = telcoTrain,
method = "knn",
trControl = train_control,
tuneGrid = optimal_k)
print(knn_model_optimal)
# Load necessary libraries
library(MASS)
# Train the LDA model using tenure and TotalCharges as predictors
lda_model <- lda(Churn ~ tenure + TotalCharges, data = telcoTrain)
# Display the LDA model summary
print(lda_model)
# To see the coefficients of linear discriminants
lda_model$scaling
library(MASS)
# Train the QDA model using tenure and TotalCharges as predictors
qda_model <- qda(Churn ~ tenure + TotalCharges, data = telcoTrain)
# Display the LDA model summary
print(qda_model)
# To see the coefficients of linear discriminants
qda_model$scaling
library(MASS)
# Train the QDA model using tenure and TotalCharges as predictors
qda_model <- qda(Churn ~ tenure + TotalCharges, data = telcoTrain)
# Display the LDA model summary
print(qda_model)
# To see the coefficients of linear discriminants
qda_model$scaling
setwd("~/eclipse-workspace/DATA405")
setwd("~/eclipse-workspace/DATA405")
# Given values
sample_mean <- 32
population_sd <- 32
sample_size <- 16
confidence_level <- 0.95
# Calculate the standard error
standard_error <- population_sd / sqrt(sample_size)
# Calculate the Z value for 95% confidence (1.96 for normal distribution)
z_value <- qnorm(1 - (1 - confidence_level) / 2)
# Calculate the margin of error
margin_of_error <- z_value * standard_error
# Calculate the confidence interval
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
# Display the confidence interval
cat("95% Confidence Interval: (", lower_bound, ", ", upper_bound, ")\n")
# Set the number of random sample
n <- 1000000
# Generate random uniform numbers in the range [-5, 10]
x_samples <- runif(n, min = -5, max = 10)
# Given values
sample_mean <- 32
population_sd <- 32
sample_size <- 16
confidence_level <- 0.95
# Calculate the standard error
standard_error <- population_sd / sqrt(sample_size)
# Calculate the Z value for 95% confidence (1.96 for normal distribution)
z_value <- qnorm(1 - (1 - confidence_level) / 2)
# Calculate the margin of error
margin_of_error <- z_value * standard_error
# Calculate the confidence interval
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
# Display the confidence interval
cat("95% Confidence Interval: (", lower_bound, ", ", upper_bound, ")\n")
standard_error
z_value
# Given values
sample_mean <- 24
population_sd <- 32
sample_size <- 16
confidence_level <- 0.95
# Calculate the standard error
standard_error <- population_sd / sqrt(sample_size)
# Calculate the Z value for 95% confidence (1.96 for normal distribution)
z_value <- qnorm(1 - (1 - confidence_level) / 2)
# Calculate the margin of error
margin_of_error <- z_value * standard_error
# Calculate the confidence interval
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
# Display the confidence interval
cat("95% Confidence Interval: (", lower_bound, ", ", upper_bound, ")\n")
?p2.14
library(MPV)
help(p2.14)
#-------------
glm(formula = y ~ x, family = binomial, data = p13.2)
# Set the number of random sample
n <- 1000000
# Generate random uniform numbers in the range [-5, 10]
x_samples <- runif(n, min = 0, max = 1)
# Evaluate the function f(x) = e^sin(x) at each random sample
f_values <- exp(cos(x_samples))
# Estimate the integral: Average of f(x) times the width of the integration interval (15)
integral_estimate <- mean(f_values) * 1
# Standard deviation of the estimates
std_dev <- sd(f_values)
# 95% confidence interval calculation
confidence_level <- 0.95
z_value <- qnorm(1 - (1 - confidence_level) / 2)  # 95% confidence z-value
# Margin of error
margin_of_error <- z_value * (std_dev / sqrt(n)) * 15
# Calculate the confidence interval
lower_bound <- integral_estimate - margin_of_error
upper_bound <- integral_estimate + margin_of_error
# Display the results
cat("Integral Estimate:", integral_estimate, "\n")
cat("95% Confidence Interval: (", lower_bound, ", ", upper_bound, ")\n")
# Define the function f(x) = exp(sin(x))
f <- function(x) exp(sin(-1*x))
# Compute the integral numerically using R's integrate function
true_value <- integrate(f, lower = -5, upper = 10)
# Display the true value of the integral
cat("True value of the integral:", true_value$value, "\n")
#-------------
glm(formula = y ~ x, family = binomial, data = p13.2)
chisq.test(100000)
# Set the number of random sample
n <- 1000000
# Generate random uniform numbers in the range [-5, 10]
x_samples <- runif(n, min = 0, max = 1)
# Evaluate the function f(x) = e^sin(x) at each random sample
f_values <- exp(cos(x_samples))
# Estimate the integral: Average of f(x) times the width of the integration interval (15)
integral_estimate <- mean(f_values) * 1
# Standard deviation of the estimates
std_dev <- sd(f_values)
# 95% confidence interval calculation
confidence_level <- 0.95
z_value <- qnorm(1 - (1 - confidence_level) / 2)  # 95% confidence z-value
# Margin of error
margin_of_error <- z_value * (std_dev / sqrt(n)) * 15
# Calculate the confidence interval
lower_bound <- integral_estimate - margin_of_error
upper_bound <- integral_estimate + margin_of_error
# Display the results
cat("Integral Estimate:", integral_estimate, "\n")
cat("95% Confidence Interval: (", lower_bound, ", ", upper_bound, ")\n")
# Define the function f(x) = exp(sin(x))
f <- function(x) exp(sin(-1*x))
# Compute the integral numerically using R's integrate function
true_value <- integrate(f, lower = -5, upper = 10)
# Display the true value of the integral
cat("True value of the integral:", true_value$value, "\n")
std_dev
#-------------
glm(formula = y ~ x, family = binomial, data = p13.2)
rchisq(1000000,32)
rchisq(1000000,32)
sd(rchisq(1000000,32))
n = 1000000
rchisq(n,32)
sd(rchisq(n,32))
sd(dt(n,4))
dt(n,4)
# Calculate the likelihood function for each lambda
likelihood <- function(lambda, X1, X2, X3) {
(X1 + X2 + X3)^(lamda - 1) * exp(-x/2)
}
# Compute likelihoods for each lambda
likelihoods <- sapply(lambda_values, likelihood, X1 = X1, X2 = X2, X3 = X3)
# Observed values of X1 and X2
X1 <- 1.5
X2 <- 3.4
X3 <- 0.20
lambda1 <- 2
lambda2 <- 3
# Possible values for lambda
lambda_values <- c(lambda1, lambda2)
# Calculate the likelihood function for each lambda
likelihood <- function(lambda, X1, X2, X3) {
(X1 + X2 + X3)^(lamda - 1) * exp(-x/2)
}
# Compute likelihoods for each lambda
likelihoods <- sapply(lambda_values, likelihood, X1 = X1, X2 = X2, X3 = X3)
# Display the likelihoods
likelihoods
# Determine the lambda with the maximum likelihood
lambda_mle <- lambda_values[which.max(likelihoods)]
# Output the MLE for lambda
lambda_mle
# Calculate the likelihood function for each lambda
likelihood <- function(lambda, X1, X2, X3) {
(X1 + X2 + X3)^(lamda - 1) * exp(-x/2)
}
likelihood
# Compute likelihoods for each lambda
likelihoods <- sapply(lambda_values, likelihood, X1 = X1, X2 = X2, X3 = X3)
# a) Standard deviation of the chi-square distribution on 32 degrees of freedom
chi_square_data <- rchisq(1000000, df=32)
chi_square_std_dev <- sd(chi_square_data)
# b) Standard deviation of the t distribution on 4 degrees of freedom
t_data <- rt(1000000, df=4)
t_std_dev <- sd(t_data)
# c) Mean of the F distribution on 7 numerator and 5 denominator degrees of freedom
f_data <- rf(1000000, df1=7, df2=5)
f_mean <- mean(f_data)
# d) Standard deviation of the F distribution on 7 numerator and 5 denominator degrees of freedom
f_std_dev <- sd(f_data)
# Print results
round(chi_square_std_dev, 2)
round(t_std_dev, 2)
round(f_mean, 2)
round(f_std_dev, 2)
# Set the number of random sample
n <- 1000000
# Generate random uniform numbers in the range [-5, 10]
x_samples <- runif(n, min = 0, max = 1)
# Evaluate the function f(x) = e^sin(x) at each random sample
f_values <- exp(cos(x_samples))
# Estimate the integral: Average of f(x) times the width of the integration interval (15)
integral_estimate <- mean(f_values) * 1
# Standard deviation of the estimates
std_dev <- sd(f_values)
# 95% confidence interval calculation
confidence_level <- 0.95
z_value <- qnorm(1 - (1 - confidence_level) / 2)  # 95% confidence z-value
# Margin of error
margin_of_error <- z_value * (std_dev / sqrt(n)) * 15
# Calculate the confidence interval
lower_bound <- integral_estimate - margin_of_error
upper_bound <- integral_estimate + margin_of_error
# Display the results
cat("Integral Estimate:", integral_estimate, "\n")
cat("95% Confidence Interval: (", lower_bound, ", ", upper_bound, ")\n")
# Define the function f(x) = exp(sin(x))
f <- function(x) exp(cos(-1*x))
# Compute the integral numerically using R's integrate function
true_value <- integrate(f, lower = -5, upper = 10)
# Display the true value of the integral
cat("True value of the integral:", true_value$value, "\n")
std_dev
runif(100,0,1)
